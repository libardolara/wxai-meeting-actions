{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription Process\n",
    "\n",
    "This notebook walks through creating a proper transcription to be used in the summarization step. We will transcribe an audio file and pass the output through an LLM to add punctuation signs. Finally we will save the output to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator('< Your STT API KEY >')\n",
    "speech_to_text = SpeechToTextV1(\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "# URL of the STT Service\n",
    "speech_to_text.set_service_url('< Your STT service URL >')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text\n",
    "\n",
    "We will use the chosen model with the custom language model to generate a transcription. This process could take between 5-10mins depending on the length of the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcription\n",
    "base_model = '< Your base STT Model >' # en-US_Telephony_LSM or en-US_Multimedia_LSM\n",
    "lm_id = \"< Your custom language ID >\"\n",
    "audio_name = 'audio.mp3'\n",
    "with open(audio_name, 'rb') as audio_file:\n",
    "    speech_recognition_results = speech_to_text.recognize(\n",
    "        audio=audio_file,\n",
    "        content_type='audio/mp3', # Change if needed\n",
    "        model= base_model,\n",
    "        smart_formatting=True,\n",
    "        language_customization_id=lm_id\n",
    "    ).get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a single transcript variable\n",
    "transcript = \"\"\n",
    "for result in speech_recognition_results['results']:\n",
    "    for alternative in result['alternatives']:\n",
    "        transcript += alternative['transcript']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the complete transcript:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: \n",
      "ok okay where one steve are you there i think you're muted yes it's yeah my bad was all right so visual history analysis of the nba final project let's start let's go with the abstracts let's see ok is the objective still temporal visualization yeah yeah it's still still the same that's that's okay ok perfect and what all the keywords so keywords we have only these 4 i think i think we should add more specific visualizations into the keyword so let's add dendrogram animated bubbles animated lines bars and lines as well ok sounds good let's go with that and or so now let's move on to the introduction tell me a little bit about it okay so let's go paragraph by paragraph i think this first one it's okay you think these are the correct references that we are using this date is correct ok i think i think that that is good 3.revolution okay yeah i'll double check that but i think that that is fine as well this dupree okay i think i think this second one it's also ok let's jump into this last one uh okay there is something that we should be able to change here right so i think this wording is is a little bit off where it says that the truth is that there is that it is very hard to compare players who played in different areas and different positions i think we can do a little bit better here so i will change this last paragraph and these wording to say something around you know comparison between errors require a deeper analytics into the change of rules and players positions ok i think i think that makes more sense all right yeah ok let's let's go with that wording making sure that this well now it looks more like a comparison between errors require a deeper analytics into the change of rules and players yeah sounds good okay i think i think that's introduction yeah alright now this the next is ok background ok background ok this first paragraph looks ok to me yeah this hasn't changed second paragraph traditional positions although well known have never been strictly defined nor enforced this is true although not everyone might know the traditional positions so here let's add the 5 traditional positions steve so that will be center point guard shooting guard small forward and forward yeah that that will help a lot and where should we add those i think you just after it says yeah and background second paragraph just after it says m the well known well known positions well known yeah you can maybe at the parentheses or something that you can figure it out okay perfect so we will add those 5 traditional positions there sounds good and now the next part will be yes approach okay the approach section yeah this small section yeah this is this is ok this is still the same perfect and now datasets yeah datasets we did have a change here a big change we are not using anymore the basketball reference data set so what we should do to steve is in all the document in all in all the the the paper we should change sorry we should change where it says back basketball reference to espn analytics ok all right so good let's go with that change make sure to put the espn analytics instead yeah yeah let's let's go with that other than that let me let me scroll down this first table i think there's a change your tube since we change data sets there is no offensive rebounds or defensive rebounds so we should delete these 2 and add one that says just total rebounds ok perfect let's do that addition to that section yeah so that table one table 2 yeah this one is still the same thing yeah there is no change there ok it all right now how about a section trade point 3 table 2 i think it's 30 yeah you're right tell me a little bit about that one okay 3.2 first ok 3.evolution per position ok in this section i think i would add a paragraph ok let me let me see where was that way this chart is okay this wording is is fine is what matters this cluster names are still relevant here here we are saying that we're going to use these 2 algorithms sarimax and aic and we should spend maybe a paragraph explaining what these 2 algorithms are ok so add a paragraph here at the end of the section and explaining what sarimax and aic is ok perfect we'll make that definition to the paragraph so it helps out perfect and let's move now to section now section 3 quinter sure yeah okay so is the lebron versus michael and analysis okay here we are good with the this assessment and i think there is something maybe we can change here steve and that is explain why the first the first 15 seasons here at the end of the first paragraph we could add a sentence that says something around that we only choose this first 15 seasons because that's the amount of seasons that michael jordan played ok all right ok so i didn't the first paragraph in section treatment we will explain that we use have 15 season because that is ammount of season that michael played ok perfect sounds good yeah that is correct okay we saw employing section results perfect ok yeah section 4 and 41 ok section 4.1 i think this is fine this is just a link to the animation o change there now section 4.2 years all the brands is though michael jordan these aviations again we have the same to be solicitations i think i think i'm seeing here a lot of per mentions ok yeah so let's let's modify this so here where it says PER let's change it to player efficiency rating and then in parentheses per ok ok we'll make that change sound good perfect yeah and so we go back we ok we go down offensive box plus minus correct overall box plus minus that is correct so here i think this is an type of error it says BMP it should be bpm box plus minus and and we should also add the full word like box plus minus and then parenthesis BPM okay alright we will make the proper updates to that and then finally conclusions ohh okay i think this is i think this is all fine and there is no this conclusion are still the same yeah no changes to the conclusion perfect sounds good okay steve thank you for your time i mean i wouldn't thank you and let me know if there are any extra optics okay thank you \n"
     ]
    }
   ],
   "source": [
    "print(\"Transcription: \")\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Prompt\n",
    "\n",
    "Since the Speech to Text service doesnt add punctuation signs we need to use an LLM to generate them. This is necessary to increase the odds to generate the best summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM Cloud Credentials\n",
    "my_credentials = { \n",
    "    \"url\"    : \"https://us-south.ml.cloud.ibm.com\", \n",
    "    \"apikey\" : '< Your IBM Cloud API KEY >'\n",
    "}      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prompt template is an example for LLAMA2. You will need to tune it for your needs.\n",
    "def punctuations_prompt_llama2(transcript):\n",
    "    return ( '[INST]<<SYS>>\\nYou are a helpful, and honest assistant. Always answer as helpfully and honestly as possible. You are asked to add the punctuation signs to the given text.\\n\\n'\n",
    "            +'For example:\\n\\n'\n",
    "            +'Text:\\n'\n",
    "            +'''i wanted to share an update on project X today project X will be completed at the end of the week that's great i heard from customer Y today and they agreed to buy our product Customer Z said they will too great news all around\\n\\n'''\n",
    "            +'Output:\\n'\n",
    "            +'''I wanted to share an update on project X today. Project X will be completed at the end of the week. That's great! I heard from customer Y today, and they agreed to buy our product. Customer Z said they will too. Great news, all around.\\n\\n'''\n",
    "            +'Text:\\n'\n",
    "            +'''the goal today is to agree on a design solution i think we should consider choice 1 i agree choice 2 has the advantage that it will take less time actually that's a good point so what should we do i'm good with choice 2 me too Done\\n\\n'''\n",
    "            +'Output:\\n'\n",
    "            +'''The goal today is to agree on a design solution. I think we should consider choice 1. I agree. Choice 2 has the advantage that it will take less time. Actually, that's a good point. So, what should we do? I'm good with choice 2. Me too. Done!\\n<</SYS>>\\n\\n'''\n",
    "            +f\"Text:\\n{transcript}\\n[/INST]\\n\"\n",
    "            +'Output:\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prompt template is an example for LLAMA3. You will need to tune it for your needs.\n",
    "def punctuations_prompt(transcript):\n",
    "    return ( '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\nYou are a writting AI assistant. Always answer as honestly as possible. You are asked to add the punctuation signs to the given text.\\n\\n'\n",
    "            +'For example:\\n\\n'\n",
    "            +'Text:\\n'\n",
    "            +'''i wanted to share an update on project X today project X will be completed at the end of the week that's great i heard from customer Y today and they agreed to buy our product Customer Z said they will too great news all around\\n\\n'''\n",
    "            +'Output:\\n'\n",
    "            +'''I wanted to share an update on project X today. Project X will be completed at the end of the week. That's great! I heard from customer Y today, and they agreed to buy our product. Customer Z said they will too. Great news, all around.\\n\\n'''\n",
    "            +'Text:\\n'\n",
    "            +'''the goal today is to agree on a design solution i think we should consider choice 1 i agree choice 2 has the advantage that it will take less time actually that's a good point so what should we do i'm good with choice 2 me too Done\\n\\n'''\n",
    "            +'Output:\\n'\n",
    "            +'''The goal today is to agree on a design solution. I think we should consider choice 1. I agree. Choice 2 has the advantage that it will take less time. Actually, that's a good point. So, what should we do? I'm good with choice 2. Me too. Done!\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n'''\n",
    "            +f\"Text:\\n{transcript}\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "            +'Output:\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id    = ModelTypes.LLAMA_3_70B_INSTRUCT\n",
    "gen_parms   = None\n",
    "project_id  = '< Your watsonx.ai project ID >'\n",
    "space_id    = None\n",
    "verify      = False\n",
    "\n",
    "model = Model( model_id, my_credentials, gen_parms, project_id, space_id, verify )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the watsonx.ai parameters fixed. You may want to double-check the minimum tokens. If it is too high the model might hallucinate to meet the token demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    GenParams.MIN_NEW_TOKENS: 1000,\n",
    "    GenParams.MAX_NEW_TOKENS: 4095,\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "    GenParams.REPETITION_PENALTY: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_base_prompt = model.tokenize(prompt=punctuations_prompt(''), return_tokens=True)\n",
    "tokenized_transcript = model.tokenize(prompt=transcript, return_tokens=True)\n",
    "ntokens_prompt = tokenized_base_prompt['result']['token_count']\n",
    "ntokens_transcript = tokenized_transcript['result']['token_count']\n",
    "\n",
    "if(ntokens_prompt+ntokens_transcript*2.5 >= 4095):\n",
    "    # Coud be iterative process. Right now just splitting by 2.\n",
    "    transcript_words = transcript.split(' ')\n",
    "    _index = int(np.floor(len(transcript_words)/2))\n",
    "\n",
    "    trans1 = \" \".join(transcript_words[:_index])\n",
    "    parameters[GenParams.MIN_NEW_TOKENS] = int(model.tokenize(prompt=trans1, return_tokens=True)['result']['token_count'])\n",
    "    prompt_txt1 = punctuations_prompt(trans1)\n",
    "    generated_response1 = model.generate_text( prompt_txt1, parameters )\n",
    "\n",
    "    trans2 = \" \".join(transcript_words[_index:])\n",
    "    parameters[GenParams.MIN_NEW_TOKENS] = int(model.tokenize(prompt=trans2, return_tokens=True)['result']['token_count'])\n",
    "    prompt_txt2 = punctuations_prompt(trans2)\n",
    "    generated_response2 = model.generate_text( prompt_txt2, parameters )\n",
    "\n",
    "    generated_response = generated_response1 + \" \" + generated_response2\n",
    "else:\n",
    "    prompt_txt = punctuations_prompt(transcript)\n",
    "    generated_response = model.generate_text( prompt_txt, parameters )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok, okay. Where one, Steve, are you there? I think you're muted. Yes, it's yeah, my bad. Was all right. So, visual history analysis of the NBA final project. Let's start. Let's go with the abstracts. Let's see. Ok, is the objective still temporal visualization? Yeah, yeah, it's still still the same. That's that's okay. Ok, perfect. And what all the keywords? So, keywords, we have only these 4. I think I think we should add more specific visualizations into the keyword. So, let's add dendrogram, animated bubbles, animated lines, bars, and lines as well. Ok, sounds good. Let's go with that. And or so, now let's move on to the introduction. Tell me a little bit about it. Ok, so let's go paragraph by paragraph. I think this first one, it's okay. You think these are the correct references that we are using? This date is correct. Ok, I think I think that that is good. 3. Revolution, okay. Yeah, I'll double-check that, but I think that that is fine as well. This Dupree, I think I think this second one, it's also ok. Let's jump into this last one. Uh, okay, there is something that we should be able to change here, right? So, I think this wording is is a little bit off, where it says that the truth is that there is that it is very hard to compare players who played in different areas and different positions. I think we can do a little bit better here. So, I will change this last paragraph and these wording to say something around, you know, comparison between errors require a deeper analytics into the change of rules and players positions. Ok, I think I think that makes more sense. All right, yeah, ok. Let's let's go with that wording, making sure that this well now it looks more like a comparison between errors require a deeper analytics into the change of rules and players, yeah. Sounds good. Ok, I think I think that's introduction. Yeah, alright. Now, this the next is ok, background. Ok, background. Ok, this first paragraph looks ok to me. Yeah, this hasn't changed. Second paragraph, traditional positions, although well known, have never been strictly defined nor enforced. This is true, although not everyone might know the traditional positions. So, here, let's add the 5 traditional positions, Steve. So, that will be center, point guard, shooting guard, small forward, and forward. Yeah, that that will help a lot. And where should we add those? I think you just after it says, yeah, and background, second paragraph, just after it says, \"m the well-known positions.\" Well-known, yeah. You can maybe at the parentheses or something that you can figure it out. Ok, perfect. So, we will add those 5 traditional positions there. Sounds good. And now, the next part will be, yes, approach. Ok, the approach section, yeah. This small section, yeah. This is this is ok. This is still the same. Perfect. And now, datasets. Yeah, datasets, we did have a change here, a big change. We are not using anymore the basketball reference data set. So, what we should do to Steve is, in all the document, in all, in all the paper, we should change, sorry, we should change where it says, \"back basketball reference\" to \"ESPN analytics.\" Ok, all right. So, good. Let's go with that change. Make sure to put the ESPN analytics instead. Yeah, yeah. Let's let's go with that. Other than that, let me, let me scroll down this first table. I think there's a change, your tube, since we change data sets. There is no offensive rebounds or defensive rebounds. So, we should delete these 2 and add one that says just total rebounds. Ok, perfect. Let's do that addition to that section, yeah. So, that table one, table 2, yeah. This one is still the same thing. Yeah, there is no change there. Ok, it all right. Now, how about a section, trade point 3, table 2? I think it's 30. Yeah, you're right. Tell me a little bit about that one. Ok, 3.2, first, ok. 3. Evolution per position. Ok, in this section, I think I would add a paragraph. Ok, let me, let me see where was that way. This chart is okay. This wording is is fine. Is what matters. This cluster names are still relevant here. Here, we are saying that we're going to use these 2 algorithms, SARIMAX and AIC, and we should spend maybe a paragraph explaining what these 2 algorithms are. Ok, so add a paragraph here at the end of the section and explaining what SARIMAX and AIC is. Ok, perfect. We'll make that definition to the paragraph, so it helps out. Perfect. And let's move now to section, now section 3, quinter, sure, yeah. Okay, so is the LeBron versus Michael and analysis. Ok, here we are good with the this assessment. And I think there is something maybe we can change here, Steve, and that is explain why the first, the first 15 seasons here, at the end of the first paragraph. We could add a sentence that says something around that we only choose this first 15 seasons because that's the amount of seasons that Michael Jordan played. Ok, all right. Ok, so I didn't the first paragraph in section treatment. We will explain that we use have 15 season because that is amount of season that Michael played. Ok, perfect. Sounds good. Yeah, that is correct. Okay, we saw employing section results. Perfect. Ok, yeah. Section 4 and 4.1. Ok, section 4.1, I think this is fine. This is just a link to the animation. O change there. Now, section 4.2, years all the brands is though Michael Jordan. These aviations again, we have the same to be solicitations. I think I think I'm seeing here a lot of PER mentions. Ok, yeah. So, let's let's modify this. So, here, where it says PER, let's change it to player efficiency rating, and then in parentheses, PER. Ok, ok. We'll make that change. Sound good. Perfect. Yeah, and so we go back. We ok, we go down. Offensive box plus minus, correct. Overall box plus minus, that is correct. So, here, I think this is an type of error. It says BMP. It should be BPM, box plus minus, and and we should also add the full word like box plus minus, and then parenthesis, BPM. Okay, alright. We will make the proper updates to that. And then, finally, conclusions. Ohh, okay. I think this is, I think this is all fine. And there is no, this conclusion are still the same. Yeah, no changes to the conclusion. Perfect. Sounds good. Okay, Steve, thank you for your time. I mean, I wouldn't thank you, and let me know if there are any extra optics. Okay, thank you.\n"
     ]
    }
   ],
   "source": [
    "print(generated_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open('transcript_generated.txt','w')\n",
    "output_file.write(generated_response)\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving RAW Output (Optional)\n",
    "raw_file = open('transcript_raw.txt','w')\n",
    "raw_file.write(json.dumps(speech_recognition_results, indent=2))\n",
    "raw_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
